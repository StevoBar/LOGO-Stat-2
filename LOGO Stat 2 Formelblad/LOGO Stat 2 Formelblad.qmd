---
title: "Statistik 2: Formelblad"
format: html
footer: Slides created by S. Baraldi
scrollable: false
slide-number: true
transition: fade
transition-speed: slow
editor: visual
---

## Kommentar till formlerna 

-   Ni ska [inte]{style="color:red;"} l√§ra er dessa utantill\
-   Ni kommer att anv√§nda endast ett f√•tal av dessa formler f√∂r manuella ber√§kningar p√• datalabbar och examinationen\
-   Vi kommer dock att referera till samtliga formler i syfte att n√• en s√• god f√∂rst√•else som m√∂jligt f√∂r deras bakomliggande statistiska begrepp och hur dom till√§mpas inom t.ex. logopedi\
-   Detta formelblad fokuserar i f√∂rsta hand p√• formler applicerbara p√• kontinuerliga slumpvariabler

## Deskriptiv statistik, 1 variabel

[Stickprovsmedelv√§rde]{style="color:red;"}

$\bar{x}=\frac{\sum_{i=1}^{n} x_i}{n}$

[Stickprovsvarians]{style="color:red;"}

$s_x^2=\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n-1}$

[Stickprovsstandardavvikelse]{style="color:red;"}

$s_x=\sqrt{s_x^2}$

[Standardisering stickprov (z)]{style="color:red;"}

$z=\frac{x-\bar{x}}{s_x}$

## Deskriptiv statistik: 2 variabler 

[Stickprovskovarians]{style="color:red;"}

$s_{xy}=Cov(x,y)=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{n-1}$

[Notera alternativ formel f√∂r stickprovs]{style="color:red;"}[varians:]{style="color:green;"}

$s_{xx}=Var(x,x)=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(x_i-\bar{x})}{n-1}$\
*(jfr med motsv. formel f√∂r 1 variabel)*

[Stickprovskorrelation]{style="color:red;"}

$r_{xy}=Corr(x,y)=\frac{s_{xy}}{s_xs_y}=\frac{\sum_{alla~ data}z_xz_y}{n-1}$

## Centrala gr√§nsv√§rdessatsen {.smaller}

#### Central Limit Theorem

\
\
F√∂renklat uttryck: Om vi tar medelv√§rdet fr√•n ett tillr√§ckligt stort antal stickprov kommer dessa medelv√§rden att approximera en normalf√∂rdelning. Detta g√§ller oavsett vilken f√∂rdelning de individuella stickproven har!\
\
Approximationen kan anses vara tillr√§ckligt bra om ùëõ ‚â• 30.\
\
F√∂r regression g√§ller generellt att approximationen √§r tillr√§ckligt bra om ùëõ ‚àí ùëò ‚àí 1 ‚â• 30, d√§r ùëò= antalet f√∂rklarande variabler)

## Enkel linj√§r regression

\
[Populationsmodell]{style="color:red;"}\
$\Upsilon=\beta_0+\beta_1x_{1,i}+\epsilon_i$ $~~$ d√§r $~~$ $\epsilon\mathop{\sim}\limits^{iid}{N}(0,\sigma_\epsilon)$\

[Skattad modell]{style="color:red;"}\
$\hat{y}=b_0+b_1x$\
\
[Skattning av parametrar:]{style="color:red;"}

[Lutningen:]{style="color:green;"} $~b_1=\frac{s_{xy}}{s_x^2}=r_{xy}~\cdot~\frac{s_y}{s_x}$

[Interceptet:]{style="color:green;"} $~b_0=\bar{y}-b_1\bar{x}$

## Multipel linj√§r regression

#### (*notera att k = 1 blir enkel regression*)

\
[Populationsmodell]{style="color:red;"}\
$\Upsilon_i=\beta_0+\beta_1x_{1,i}+...+\beta_kx_{k,i}+\epsilon_i$ $~~$ d√§r $~~$ $\epsilon\mathop{\sim}\limits^{iid}{N}(0,\sigma_\epsilon)$\

[Skattad regressionsmodell]{style="color:red;"}\
$\hat{y}=b_0+b_1x_1+b_2x_2+...b_kx_k$

\
[Skattning av parametrar i MR ges av teknologi (kr√•ngliga formler)]{style="color:purple;"}

## Normalf√∂rdelning med standardisering

::: columns
::: {.column width="50%"}
\
[Teori:]{style="color:red;"}\

$f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}$\
\
$X\sim\mathcal{N}(\mu,\sigma)$
:::

::: {.column width="50%"}
$E(X)=\mu$\
\
$Var(X)=\sigma^2$\
\
[Standardisering:]{style="color:red;"}\

$Z=\frac{X-\mu}{\mu}\sim{N}(0,1)$\

d√§r $Z$ √§r kritiskt v√§rde
:::
:::

## Normalkurvan

\
![](Normalkurvan.png){width="800," height="500"}

## Student t-f√∂rdelning

::: columns
::: {.column width="50%"}
\
\
\

$X\sim t(v)$\
\

d√§r $t$ √§r kritiskt v√§rde och $v$ √§r antalet frihetsgrader
:::

::: {.column width="50%"}
\

![](t-kurvan.png){width="400," height="400"}
:::
:::

## $\chi^2$-f√∂rdelning

::: columns
::: {.column width="50%"}
\
\
\
$X\sim\chi^2(v)$\
\
d√§r $v$ √§r antalet frihetsgrader
:::

::: {.column width="50%"}
\
\
![](Chi-tv√•-kurvan.png){width="500," height="300"}
:::
:::

## Inferens f√∂r population

::: columns
::: {.column width="50%"}
\
[Teststatistika med k√§nd varians]{style="color:red;"}\

$Z=\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}$\
\
[Teststatistika med ok√§nd varians]{style="color:red;"}\

$T=\frac{\bar{X}-\mu_0}{s_x/\sqrt{n}}$
:::

::: {.column width="50%"}
\
[Konfidensintervall v√§ntev√§rde med k√§nd varians]{style="color:red;"}\

$\bar{x}\pm z_{\alpha/2}\cdot\frac{\sigma}{\sqrt{n}}$\
\

[Konfidensintervall v√§ntev√§rde med ok√§nd varians]{style="color:red;"}\

$\bar{x}\pm t_{\alpha/2, n-1}\cdot\frac{s_x}{\sqrt{n}}$
:::
:::

## Inferens: J√§mf√∂ra tv√• oberoende grupper

\
[Teststatistika]{style="color:red;"}\
\
$T=\frac{\bar{X_1}-{\bar{X_0}}}{\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_0}{n_0}}}$

\
[Frihetsgraderna i en t-f√∂rdelning ges av teknologi (kr√•ngliga formler)]{style="color:red;"}

## Inferens: J√§mf√∂ra tv√• beroende grupper

\

Data som differenser

\
[Teststatistika f√∂r parade data]{style="color:red;"}\
\
$T=\frac{\bar{D}}{S_D/\sqrt{n}}$

## Inferens: $\chi^2$

::: columns
::: {.column width="50%"}
\
\
\
[Teststatistika]{style="color:red;"}\
\
$\chi^2=\sum\limits_{Alla~celler}\frac{(Obs-Exp)^2}{Exp}$
:::

::: {.column width="50%"}
[Frihetsgrader f√∂r goodness-of-fit]{style="color:red;"}

$v=k-1$\

*d√§r k √§r antal celler i tabellen*

[Frihetsgrader f√∂r test av oberoende]{style="color:red;"}

$v=(C-1)\cdot(R-1)$

*d√§r C √§r antal kolumner och R √§r antal rader*
:::
:::

